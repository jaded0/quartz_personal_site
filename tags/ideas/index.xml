<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>ideas on</title><link>https://jadenlorenc.com/tags/ideas/</link><description>Recent content in ideas on</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><atom:link href="https://jadenlorenc.com/tags/ideas/index.xml" rel="self" type="application/rss+xml"/><item><title>Candidate Weight Changes</title><link>https://jadenlorenc.com/Candidate-Weight-Changes/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://jadenlorenc.com/Candidate-Weight-Changes/</guid><description>#hebbian #ideas
[[2024-01-30]]
My loss graph looks wild:
![[/files/W&amp;amp;BChart1_30_202485501AM.png|600]]
Weights &amp;amp; Biases
I attribute the wave pattern to the self-reinforcing [[Hebbian Learning|weight updates]] improving performance quickly when they&amp;rsquo;ve found something right, then rapidly diverging because of biases inherent in that pattern being magnified and getting out of control.</description></item><item><title>Cyclic Plasticity Values</title><link>https://jadenlorenc.com/Cyclic-Plasticity-Values/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://jadenlorenc.com/Cyclic-Plasticity-Values/</guid><description>#hebbian #ideas
Inspired by a youtube video by Artem Kirsanov (I think it might be this one), which describes how biological neurons have a 6hr period of varying plasticity, and each might be most plastic at a different time than the rest.</description></item><item><title>HPCA</title><link>https://jadenlorenc.com/HPCA/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://jadenlorenc.com/HPCA/</guid><description>#hebbian #phd
[[2024-02-07]]
An extension to [[Ojas Rule]], pulling the principle of extracting the main direction from the data, out into the space for more than just one neuron at a time.</description></item></channel></rss>